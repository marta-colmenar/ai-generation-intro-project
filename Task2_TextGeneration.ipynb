{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "957f08ca",
   "metadata": {},
   "source": [
    "# TASK 2 — Text Generation with GPT-2\n",
    "I am sure you've heard and even used AI text generation tools like ChatGPT. These tools can generate human-like text based on a prompt you provide. In this task, we will explore how to use a pre-trained language model called GPT-2 to generate text. So by the end of this task, you will be able to create your own text generation scripts! And have a bit of understanding of it's limitations and how they work.\n",
    "\n",
    "\n",
    "Let's start first playing with it. Go to [Hugging Face's GPT-2 Text Generation Demo](https://huggingface.co/openai-community/gpt2) and try to generate a history or you can also see the posible combinations with the [BERT visualizer](https://huggingface.co/spaces/exbert-project/exbert). See what kind of text the model generates. You can try different styles, topics, or even languages! Take a look at the model openAI page explaining a bit the model [here](https://openai.com/index/better-language-models/).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b2ef24",
   "metadata": {},
   "source": [
    "### Video for this Task\n",
    "\n",
    "Before we start generating text, check out this short video to understand what GPT-2 does!\n",
    "\n",
    "[Watch: How GPT-2 Generates Text](https://www.youtube.com/watch?v=Zpu4mubO_qE)\n",
    "\n",
    "Take a few minutes to watch it — it explains in simple terms how AI can write stories, messages, or prompts just like a human!\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec865df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27dfc13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded!\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Create a text-generation pipeline using gpt2 (small, fast).\n",
    "# First run may download the model (~500MB). Be patient.\n",
    "print('Loading model...')\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "print('Model loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b44c801f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Option 1:\n",
      "My dream job is to help people find their own place in humanity.\n",
      "\n",
      "\"We are not going to let us down. We are going to make progress, and make it better. We will make things better for\n",
      "\n",
      "Option 2:\n",
      "My dream job is to keep the world on our side, and I'm really excited to be working with you to help us get there.\"\n",
      "\n",
      "As to what the future holds, the U.S. government is\n",
      "\n",
      "Option 3:\n",
      "My dream job is to create an environment where people have the ability to say \"Yes\" to the possibility of a possible future in the United States. It's an optimistic outlook, and the hope is that it will create\n",
      "\n",
      "Option 4:\n",
      "My dream job is to make a good team. I love to play, and I want to play well. It's a challenge for me to try to win, but I'm happy to be playing. I'm willing\n",
      "\n",
      "Option 5:\n",
      "My dream job is to make the world a better place. I want to do it all within the same frame of mind,\" she said.\n",
      "\n",
      "The former first lady, who was born in India and raised in the\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Experiment 1: Basic prompt completion\n",
    "prompt = \"My dream job is\"\n",
    "outputs = generator(prompt, max_new_tokens=40, num_return_sequences=5, truncation=True)\n",
    "\n",
    "for i, out in enumerate(outputs):\n",
    "    print(f\"Option {i+1}:\\n{out['generated_text']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1a5e066",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Option 1:\n",
      "In a future where robots help humans, we're going to have to rethink how we live.\n",
      "\n",
      "Robots are a great tool for solving complex issues, but in the future, we're going to have to rethink how we live.\n",
      "\n",
      "The most interesting thing about artificial intelligence is that we're now in a world where we're\n",
      "\n",
      "Option 2:\n",
      "In a future where robots help humans, they will have to learn how to use the robots.\n",
      "\n",
      "In a future where robots help humans, they will have to learn how to use the robots. They'll have to work on the robot's abilities to make it work. They'll have to be able to figure out how to use them\n",
      "\n",
      "Option 3:\n",
      "In a future where robots help humans, it's hard to see why such a thing would be necessary.\"\n",
      "\n",
      "The research did not take place in the lab and the findings are being shared by other researchers at the University of California, Berkeley.\n",
      "\n",
      "\"We're going to explore whether this is a viable option for the future of robotic\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Try changing the prompt below and re-run this cell.\n",
    "prompt = \"In a future where robots help humans,\"\n",
    "outputs = generator(prompt, max_new_tokens=60, num_return_sequences=3, truncation=True)\n",
    "for i, out in enumerate(outputs):\n",
    "    print(f\"Option {i+1}:\\n{out['generated_text']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8673c47c",
   "metadata": {},
   "source": [
    "### Tweakable settings (try changing these values and re-run the previous cell):\n",
    "\n",
    "- `max_new_tokens`: how long the generated text can be (higher = longer).  \n",
    "- `num_return_sequences`: how many different completions to generate.  \n",
    "- `temperature`: creativity (0.1 = conservative, 1.0 = default, >1 = more random).  \n",
    "- `top_k` / `top_p`: control sampling diversity.\n",
    "\n",
    "Example with temperature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee5dce6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Option 1:\n",
      "The secret to making a good cake is not just to bake it, but to make it so good that it is delicious. The cake is simply to make you happy.\n",
      "\n",
      "When you bake a cake, you make it as good as you can. You bake it on a low temperature\n",
      "\n",
      "Option 2:\n",
      "The secret to making a good cake is to make sure that it's baked properly, so that it doesn't go too dry.\n",
      "\n",
      "1. Heat a large skillet over medium-high heat. Add the butter and sauté until softened, about 1 minute. Add the flour and\n",
      "\n",
      "Option 3:\n",
      "The secret to making a good cake is to get it from the right place.\n",
      "\n",
      "When I was young, I wanted to make cakes with white sugar in them. That was the first time I ever made a cake with white sugar in it. I used to have a cake recipe that\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Experiment 2: Play with sampling parameters\n",
    "prompt = \"The secret to making a good cake is\"\n",
    "outputs = generator(prompt, max_new_tokens=50, do_sample=True, temperature=0.7, top_p=0.9, num_return_sequences=3, truncation=True)\n",
    "for i, out in enumerate(outputs):\n",
    "    print(f\"Option {i+1}:\\n{out['generated_text']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61815f9a",
   "metadata": {},
   "source": [
    "### Quick notes (playground tips)\n",
    "- If the model starts repeating, try lowering `temperature` or increasing `top_p`.  \n",
    "- Use short prompts for surprise, longer prompts for guided completions.  \n",
    "- If running locally and download is slow, try running once and then re-running later (model caches).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "015d676c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Option 1:\n",
      "Write a short, friendly message to a new student joining a science lab:\n",
      "\n",
      "\"If you want to do that, you should at least write a short, friendly note. This will be helpful!\"\n",
      "\n",
      "If you want to take the opportunity to share your experience with someone else you will, of course, try the following solutions for those who have difficulty:\n",
      "\n",
      "1) Use the online social networking site, LinkedIn.com, where you can get your students interested\n",
      "\n",
      "Option 2:\n",
      "Write a short, friendly message to a new student joining a science lab:\n",
      "\n",
      "Sprint Email a message to a new student who is already a science student, or send it to a new student.\n",
      "\n",
      "Start a new group of students to share these new interests:\n",
      "\n",
      "Start a new group of students to share these new interests at http://sciencelab.cs.ucsd.edu/.\n",
      "\n",
      "And see what other students have posted online:\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Try your own prompts here! Replace the prompt string and run.\n",
    "my_prompt = \"Write a short, friendly message to a new student joining a science lab:\"\n",
    "outputs = generator(my_prompt,max_new_tokens=80,do_sample=True,temperature=0.9,num_return_sequences=2,truncation=True)\n",
    "\n",
    "for i, out in enumerate(outputs):\n",
    "    print(f\"Option {i+1}:\\n{out['generated_text']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774f409c",
   "metadata": {},
   "source": [
    "## Exercises (pick a few)\n",
    "1. Give the model a creative prompt (story beginning) and generate 3 different continuations. Which one do you like best?  \n",
    "2. Change `temperature` to 0.2, 0.7, and 1.2 for the same prompt — how do outputs differ?  \n",
    "3. Try a prompt in another language (e.g., German). Does GPT-2 respond sensibly?  \n",
    "4. (Optional) Try `gpt2-medium`, `gpt2-large` or `gpt2-xl` if you want longer/more fluent outputs (requires more RAM)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
